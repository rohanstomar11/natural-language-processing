{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cc0a6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules Imported Successfully!\n"
     ]
    }
   ],
   "source": [
    "#Import Modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "print(\"Modules Imported Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "651374ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the Dataset\n",
    "df = pd.read_csv('capitals.txt', delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6595d6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['city1', 'country1', 'city2', 'country2'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Renaming the column names\n",
    "df.columns=[\"city1\", \"country1\", \"city2\", \"country2\"]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0d9223c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city1</th>\n",
       "      <th>country1</th>\n",
       "      <th>city2</th>\n",
       "      <th>country2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Bern</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>Egypt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    city1 country1    city2     country2\n",
       "0  Athens   Greece  Bangkok     Thailand\n",
       "1  Athens   Greece  Beijing        China\n",
       "2  Athens   Greece   Berlin      Germany\n",
       "3  Athens   Greece     Bern  Switzerland\n",
       "4  Athens   Greece    Cairo        Egypt"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83a3a398",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = pickle.load(open(\"word_embeddings_subset.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fa0ef29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68d5c586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate cosine similarity\n",
    "def cosine_similarity(A, B):\n",
    "    \"\"\"sum = 0 #Initialising the sum to 0\n",
    "    for x,y in zip(A,B): #Iterating on both the lists together\n",
    "        sum += x*y #adding sum and product of each element at ith poisition\n",
    "    norm_a, norm_b = np.linalg.norm(A), np.linalg.norm(B) #calculating norm of A and B \n",
    "    cos_b = sum/(norm_a*norm_b) #calculating cos(beta)\n",
    "    return cos_b\"\"\"\n",
    "    \n",
    "    dot = np.dot(A,B) #dot product of A & B\n",
    "    norm_a = np.sqrt(np.dot(A,A)) #magnitude of A\n",
    "    norm_b = np.sqrt(np.dot(B,B)) #magnitude of B\n",
    "    return dot/(norm_a*norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1041573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6510956"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing our cosine similarity function\n",
    "king = word_embeddings[\"king\"] #getting the word embeddings for the word\n",
    "queen = word_embeddings[\"queen\"]\n",
    "\n",
    "cosine_similarity(king, queen) #calculating the cosine similarity between the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a85acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the country of inputs\n",
    "def get_country(city1, country1, city2, word_embeddings):\n",
    "    \n",
    "    #getting the word embeddings for our input\n",
    "    city1_emb = word_embeddings[city1] \n",
    "    country1_emb = word_embeddings[country1]\n",
    "    city2_emb = word_embeddings[city2]\n",
    "    \n",
    "    vec = country1_emb - city1_emb + city2_emb #getting the embeddings for our prediction \n",
    "    \n",
    "    similarity = -1 #initialising the similarity to -1\n",
    "    country = '' #initialising an empty string for country\n",
    "    \n",
    "    group = set((city1, country1, city2)) #input set\n",
    "    \n",
    "    for word in word_embeddings.keys(): #iterating through words in embedddings\n",
    "        \n",
    "        if word not in group: #in order to not get any input country as output\n",
    "            word_emb = word_embeddings[word] #get the word embeddings\n",
    "            cos_similarity = cosine_similarity(vec, word_emb) #getting the cosine similarity for the word vector and predicted vectore\n",
    "            \n",
    "            if cos_similarity > similarity: #if current word similarity is greater\n",
    "                similarity = cos_similarity #new similarity => current similarity\n",
    "                country = (word, similarity) #changing country to (country, similarity) pair\n",
    "                \n",
    "    return country\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b1122af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Switzerland', 0.5022102)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_country('Athens', 'Greece', 'Bern', word_embeddings) #checking our get_country function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d14dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(word_embeddings, data):\n",
    "    num_correct = 0 #to count the right predictions\n",
    "    \n",
    "    for i, row in data.iterrows(): #for iterating through rows of our data\n",
    "        \n",
    "        city1 = row[\"city1\"] #getting the city1 column\n",
    "        country1 = row[\"country1\"]\n",
    "        city2 = row[\"city2\"]\n",
    "        country2 = row[\"country2\"] #output country\n",
    "        \n",
    "        country2_pred, _ = get_country(city1, country1, city2, word_embeddings) #get country for current group\n",
    "        \n",
    "        if country2_pred == country2: #if predicted country is equal to actual country\n",
    "            num_correct += 1 #increase the nnumber of accurate predictions\n",
    "        \n",
    "    m = len(data) #total length of data\n",
    "    accuracy = num_correct/m #calculating accuracy\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94e1912b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.92 %\n"
     ]
    }
   ],
   "source": [
    "print(round(get_accuracy(word_embeddings, df),4)*100, \"%\") #getting the accuracy of our predictor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
