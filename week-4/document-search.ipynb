{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a4d6519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import twitter_samples, stopwords\n",
    "import pickle\n",
    "import numpy as np\n",
    "from package import process_tweets, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e024a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "\n",
    "all_tweets = positive_tweets + negative_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f43cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_embeddings = pickle.load(open('en_embeddings.p', 'rb')) #english word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26274916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_embedding(tweet, en_embeddings):\n",
    "    \n",
    "    doc_embedding = np.zeros(300)\n",
    "    \n",
    "    processed_doc = process_tweets(tweet)\n",
    "    \n",
    "    for word in processed_doc:\n",
    "        doc_embedding += en_embeddings.get(word, 0)\n",
    "    \n",
    "    return doc_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90d2d141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00268555, -0.15378189, -0.55761719, -0.07216644, -0.32263184])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_tweet = \"RT @Twitter @chapagain Hello There! Have a great day. :) #good #morning http://chapagain.com.np\"\n",
    "\n",
    "tweet_embedding = get_document_embedding(custom_tweet, en_embeddings)\n",
    "tweet_embedding[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "116d76d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_vecs(docs, embeddings):\n",
    "    \n",
    "    doc_dict = {}\n",
    "    \n",
    "    doc_vecs = []\n",
    "    \n",
    "    for i, doc in enumerate(docs):\n",
    "        doc_embedding = get_document_embedding(doc, embeddings)\n",
    "        \n",
    "        doc_dict[i] = doc_embedding\n",
    "        \n",
    "        doc_vecs.append(doc_embedding)\n",
    "        \n",
    "    doc_matrix = np.vstack(doc_vecs)\n",
    "    \n",
    "    return doc_matrix, doc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "527dc671",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_matrix, doc_dict = get_document_vecs(all_tweets, en_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "315d1c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dictionary:  10000\n",
      "Document vecs shape:  (10000, 300)\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of dictionary: \", len(doc_dict))\n",
    "print(\"Document vecs shape: \", doc_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2ad3ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sad']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tweet = \"i am sad\"\n",
    "process_tweets(my_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bae67b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_embedding = get_document_embedding(my_tweet, en_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca9252e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@zoeeylim sad sad sad kid :( it's ok I help you watch the match HAHAHAHAHA\n"
     ]
    }
   ],
   "source": [
    "max_id = np.argmax(cosine_similarity(doc_matrix, tweet_embedding))\n",
    "print(all_tweets[max_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "612fff48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 300\n"
     ]
    }
   ],
   "source": [
    "N_VECS = len(all_tweets) #no. of vectors\n",
    "N_DIMS = len(doc_dict[1]) #dimension in each vector\n",
    "print(N_VECS,N_DIMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68ce155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PLANES = 10 #no. of planes\n",
    "N_UNIVERSES = 25 #no. of times to repeat the hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ae82989",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(11)\n",
    "planes_l = [np.random.normal(size=(N_DIMS, N_PLANES)) for _ in range(N_UNIVERSES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afbdbec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_value_of_vector(v, planes):\n",
    "    \n",
    "    dot_product = np.dot(v, planes)\n",
    "    \n",
    "    sign_dot = np.sign(dot_product)\n",
    "    \n",
    "    h = sign_dot>=0\n",
    "    \n",
    "    h = np.squeeze(h)\n",
    "    \n",
    "    hash_value = 0\n",
    "    \n",
    "    n_planes = planes.shape[1]\n",
    "    \n",
    "    for i in range(n_planes):\n",
    "        hash_value += 2**i * h[i]\n",
    "    \n",
    "    return int(hash_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "271a2e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The hash value for this vector, and the set of planes at index 1, is 43\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(11)\n",
    "ids = 1\n",
    "planes = planes_l[ids]  # get one 'universe' of planes to test the function\n",
    "vec = np.random.rand(1, 300)\n",
    "print(f\" The hash value for this vector,\",\n",
    "      f\"and the set of planes at index {ids},\",\n",
    "      f\"is {hash_value_of_vector(vec, planes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "975965ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hash_table(vec, planes):\n",
    "    \n",
    "    n_planes = planes.shape[1]\n",
    "    \n",
    "    n_buckets = 2**n_planes\n",
    "    \n",
    "    hash_table = {i:[] for i in range(n_buckets)}\n",
    "    \n",
    "    id_table = {i:[] for i in range(n_buckets)}\n",
    "    \n",
    "    for i,v in enumerate(vec):\n",
    "        h = hash_value_of_vector(v, planes)\n",
    "        hash_table[h].append(v)\n",
    "        id_table[h].append(i)\n",
    "        \n",
    "    return hash_table, id_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41bea569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 10) \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(11)\n",
    "planes= planes_l[0]\n",
    "vec = np.random.rand(1,300)\n",
    "print(planes.shape, '')\n",
    "\n",
    "hash_table_temp , id_table_temp = make_hash_table(vec, planes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "144430ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hash_table_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "626c1036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_table_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8455b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on hash universe : # 0\n",
      "Working on hash universe : # 1\n",
      "Working on hash universe : # 2\n",
      "Working on hash universe : # 3\n",
      "Working on hash universe : # 4\n",
      "Working on hash universe : # 5\n",
      "Working on hash universe : # 6\n",
      "Working on hash universe : # 7\n",
      "Working on hash universe : # 8\n",
      "Working on hash universe : # 9\n",
      "Working on hash universe : # 10\n",
      "Working on hash universe : # 11\n",
      "Working on hash universe : # 12\n",
      "Working on hash universe : # 13\n",
      "Working on hash universe : # 14\n",
      "Working on hash universe : # 15\n",
      "Working on hash universe : # 16\n",
      "Working on hash universe : # 17\n",
      "Working on hash universe : # 18\n",
      "Working on hash universe : # 19\n",
      "Working on hash universe : # 20\n",
      "Working on hash universe : # 21\n",
      "Working on hash universe : # 22\n",
      "Working on hash universe : # 23\n",
      "Working on hash universe : # 24\n"
     ]
    }
   ],
   "source": [
    "hash_tables = []\n",
    "id_tables = []\n",
    "for universe in range(N_UNIVERSES):\n",
    "    print(\"Working on hash universe : #\", universe)\n",
    "    planes = planes_l[universe]\n",
    "    hash_table, id_table = make_hash_table(doc_matrix, planes)\n",
    "    hash_tables.append(hash_table)\n",
    "    id_tables.append(id_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4a724fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 1 (212121665.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [22]\u001b[1;36m\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 1\n"
     ]
    }
   ],
   "source": [
    "def approximate_knn(doc_id, v, planes_l, k=1, num_universes_to_use=N_UNIVERSES):\n",
    "    \n",
    "    vecs_to_consider_l = list()\n",
    "    ids_to_consider_l = list()\n",
    "    \n",
    "    ids_to_consider_set =  set()\n",
    "    \n",
    "    for universe_id in range(num_universes_to_use):\n",
    "        \n",
    "        planes = planes_l[universe_id]\n",
    "        \n",
    "        hash_value_of_vector = (v, planes)\n",
    "        \n",
    "        hash_table = hash_tables[universe_id]\n",
    "        \n",
    "        document_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811f37a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
